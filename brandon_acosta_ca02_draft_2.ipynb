{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acostabrandon/BSAN-6070/blob/main/brandon_acosta_ca02_draft_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CyLHsJQB_1M8"
      },
      "outputs": [],
      "source": [
        "#import necessary libraries\n",
        "import numpy as np\n",
        "import os\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from google.colab import drive #for google drive integration\n",
        "from sklearn.naive_bayes import MultinomialNB #multinomial naive bayes model for text classification\n",
        "from sklearn.metrics import accuracy_score #for testing accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJwKaSI0M7-o",
        "outputId": "87d74227-adac-4499-c8ec-4e2424fee2e3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dictionary Function\n",
        "This function starts by extracting the 3,000 most common words from all the emails in the training folder. It also removes any single-character words and non-alphabetical instances. The list that is outputed by this function will allow us to do feature extraction."
      ],
      "metadata": {
        "id": "me_IPIiW-MIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_Dictionary(root_dir):\n",
        "  all_words = []\n",
        "  emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)]\n",
        "  for mail in emails:\n",
        "    with open(mail) as m:\n",
        "      for line in m:\n",
        "        words = line.split()\n",
        "        all_words += words\n",
        "  dictionary = Counter(all_words)\n",
        "  list_to_remove = list(dictionary)\n",
        "\n",
        "  for item in list_to_remove:\n",
        "    if item.isalpha() == False:\n",
        "      del dictionary[item]\n",
        "    elif len(item) == 1:\n",
        "      del dictionary[item]\n",
        "  dictionary = dictionary.most_common(3000)\n",
        "  return dictionary"
      ],
      "metadata": {
        "id": "N8JL8rDpADUz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Features Function\n",
        "This function reads all the emails in the training data set and converts each individual email into a \"features matrix\" using the top 3,000 words. It then counts each unique occurence (value counts) of each word and uploads it into the matrix. Then, based on the file name (such as the presence of 'spmsg'), it will return the number 1 for spam emails, and the number 0 for non-spam emails."
      ],
      "metadata": {
        "id": "AVWzrd0z-4yr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(mail_dir):\n",
        "  files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)]\n",
        "  features_matrix = np.zeros((len(files),3000))\n",
        "  train_labels = np.zeros(len(files))\n",
        "  count = 1;\n",
        "  docID = 0;\n",
        "  for fil in files:\n",
        "    with open(fil) as fi:\n",
        "      for i, line in enumerate(fi):\n",
        "        if i ==2:\n",
        "          words = line.split()\n",
        "          for word in words:\n",
        "            wordID = 0\n",
        "            for i, d in enumerate(dictionary):\n",
        "              if d[0] == word:\n",
        "                wordID = i\n",
        "                features_matrix[docID,wordID] = words.count(word)\n",
        "      train_labels[docID] = 0;\n",
        "      filepathTokens = fil.split('/')\n",
        "      lastToken = filepathTokens[len(filepathTokens)-1]\n",
        "      if lastToken.startswith(\"spmsg\"):\n",
        "        train_labels[docID] = 1;\n",
        "        count = count + 1\n",
        "      docID = docID + 1\n",
        "  return features_matrix, train_labels"
      ],
      "metadata": {
        "id": "XwjZgSxEDB7H"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paths using Google Drive to train folder and test folder."
      ],
      "metadata": {
        "id": "oCQPPJrq_Xma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_DIR = '/content/drive/MyDrive/BSAN6070/train-mails'\n",
        "TEST_DIR = '/content/drive/MyDrive/BSAN6070/test-mails'"
      ],
      "metadata": {
        "id": "2WbMHN1qZTmh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Testing using Naive Bayes Model\n",
        "The following block of code fills out the incomplete data from the one provided using the features matrix and train labels previously outputed by the two previous functions. Furthermore, it runs the model using Multinomial NB and tests the model for accuracy, providing a final accuracy score for the model."
      ],
      "metadata": {
        "id": "7_Edws5a_xo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we start by using the make_Dictionary function to create the list of 3,000 most common words in the training data folder.\n",
        "dictionary = make_Dictionary(TRAIN_DIR)\n",
        "\n",
        "#we then use the extract_features function previously created using both the training and test dataset\n",
        "print('Reading and processing emails from TRAIN and TEST folders.')\n",
        "features_matrix, labels_train = extract_features(TRAIN_DIR)\n",
        "test_features_matrix, labels_test = extract_features(TEST_DIR)\n",
        "\n",
        "print('Training model using Multinomial Naive Bayes algorithm.')\n",
        "model = MultinomialNB() #train the spam email classifier using Naive Bayes from SciKit Learn\n",
        "model.fit(features_matrix, labels_train)\n",
        "\n",
        "print('Training completed \\n Testing trained model to predict test data labels.')\n",
        "labels_predicted = model.predict(test_features_matrix) #this compares the predictions from the model to the test dataset matrix\n",
        "accuracy = accuracy_score(labels_test, labels_predicted) #computes accuracy score\n",
        "\n",
        "print('Completed classification of the test data... now printing Accuracy Score by comparing the predicted labels with the test labels:')\n",
        "print(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCDoBLMaEcbc",
        "outputId": "6672f3c3-d425-48a0-ce4f-e42b5c24da6f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading and processing emails from TRAIN and TEST folders.\n",
            "Training model using Multinomial Naive Bayes algorithm.\n",
            "Training completed \n",
            " Testing trained model to predict test data labels.\n",
            "Completed classification of the test data... now printing Accuracy Score by comparing the predicted labels with the test labels:\n",
            "0.9615384615384616\n"
          ]
        }
      ]
    }
  ]
}